{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c6d0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import json\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns=1000\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efa47db",
   "metadata": {},
   "source": [
    "# 1. merge all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2009ee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_dict = {}  #insert matching dict here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5434c03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_file = 'export_group_assignment_small.csv'\n",
    "df = pd.read_csv('data/small/export_group_assignment_small.csv')\n",
    "df = df[matching_dict[primary_file]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625a4067",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = '_'.join([x for x in primary_file.split('_') if ('export' not in x) & ('small' not in x)])\n",
    "df.columns = [table_name + '_' + x if (x != 'group_id') &  (x != 'client_id') else x for x in df.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c5ab7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicated rows\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f03cd9",
   "metadata": {},
   "source": [
    "# 2. feature engineering: stage 1 model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0993935",
   "metadata": {},
   "source": [
    "## 2.1 time_diff_group_lead_creation\n",
    "categorical difference between group_assignment_created_at and client_funnel_lead_created_at\n",
    "- no diff: 0\n",
    "- less than 10 min: 1\n",
    "- more than 10min: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d165bfd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['group_assignment_created_at'] = df['group_assignment_created_at'].apply(lambda x: pd.to_datetime(x.replace('Z', '').strip()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca30d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['client_funnel_lead_created_at'] = df['client_funnel_lead_created_at'].apply(lambda x: pd.to_datetime(str(x).replace('Z', '').strip()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acec7467",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time_diff_group_lead_creation'] = df['group_assignment_created_at'] - df['client_funnel_lead_created_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0972fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#investigate what buckets i should create\n",
    "\n",
    "timediff_count = df['time_diff_group_lead_creation'].value_counts().reset_index()\n",
    "timediff_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecd8acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sameday_mask = timediff_count['index'].apply(lambda x: x.days == 0)\n",
    "sameday_diffhours = timediff_count[sameday_mask]['index'].apply(lambda x: round(x / np.timedelta64(1, 'h')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bfab36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(sameday_diffhours, bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3be0409",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffday_mask = timediff_count['index'].apply(lambda x: x.days != 0)\n",
    "diffday_days = timediff_count[diffday_mask]['index'].apply(lambda x: round(x.days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63eabd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(diffday_days, bins=40, range=(0,400))  #zoom the histogram in to investigate further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3736c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timediff_category(x):\n",
    "    total_seconds = x.total_seconds()\n",
    "    num_hours = x.total_seconds() / 60 / 60\n",
    "    num_days = x.days\n",
    "    \n",
    "    if np.isnan(total_seconds):\n",
    "        return 0  #cannot calculate a timediff \n",
    "    if total_seconds == 0:  #no timediff at all\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "df['timediff_category_group_lead_creation'] = df['time_diff_group_lead_creation'].apply(lambda x: get_timediff_category(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ae31e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['timediff_category_group_lead_creation'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b6fe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('time_diff_group_lead_creation', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c267da85",
   "metadata": {},
   "source": [
    "## 2.2 client_funnel_first_touch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eace68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def get_dict(x):\n",
    "    try:\n",
    "        return ast.literal_eval(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df['client_funnel_first_touch_dict'] = df['client_funnel_first_touch'].apply(lambda x: get_dict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66fd15a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_time(x):\n",
    "    try:\n",
    "        return pd.to_datetime(x['created_at'].replace('Z', '').strip())\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df['client_funnel_first_touch_time'] = df['client_funnel_first_touch_dict'].apply(lambda x: get_time(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d35ec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timediff'] = df['client_funnel_lead_created_at'] - df['client_funnel_first_touch_time']  #lead is created after first touch recorded!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2067e21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_days(x):\n",
    "    try:\n",
    "        return round(x.days)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "days = df['timediff'].apply(lambda x: get_days(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40949f0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "days.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e2dff5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(days, range=(-100,100), bins=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683760c6",
   "metadata": {},
   "source": [
    "## 2.3 timediff_firsttouch_leadcreation\n",
    "time difference between first touch timestamp and lead creation timestamp\n",
    "- no timediff data avai: 0\n",
    "- more than 1 day before: 1\n",
    "- 1 day before: 2\n",
    "- same day: 3\n",
    "- after same day: 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51076c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category(x):\n",
    "    try:\n",
    "        day = round(x.days)\n",
    "    except:\n",
    "        return 0\n",
    "    if day < -1:\n",
    "        return 1\n",
    "    if day == -1:\n",
    "        return 2\n",
    "    if day == 0:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "df['timediff_firsttouch_leadcreation'] = df['timediff'].apply(lambda x: get_category(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e77d36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timediff_firsttouch_leadcreation'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad4b46a",
   "metadata": {},
   "source": [
    "## 2.4. client_funnel_first_touch_medium\n",
    "medium on which the first touch took place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071c93a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_medium(x):\n",
    "    try:\n",
    "        return x['category']['description']\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df['client_funnel_first_touch_medium'] = df['client_funnel_first_touch_dict'].apply(lambda x: get_medium(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aea1c6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['client_funnel_first_touch_medium'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21682318",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all intermediate cols created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2f6193",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['client_funnel_first_touch_dict', 'client_funnel_first_touch_time', 'timediff'], axis='columns', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6615729b",
   "metadata": {},
   "source": [
    "## 2.5. client_funnel_layout_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bcfed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['client_funnel_layout_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd58c003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_layout(x):\n",
    "    if type(x) != str:\n",
    "        return 'Unknown'\n",
    "    if x == '(Unknown)':\n",
    "        return 'Unknown'\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "df['client_funnel_layout_type'] = df['client_funnel_layout_type'].apply(lambda x: clean_layout(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4f03e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['client_funnel_layout_type'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb392302",
   "metadata": {},
   "source": [
    "## 2.6. client_funnel_client_lead_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641b856f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def get_dict(x):\n",
    "    try:\n",
    "        return ast.literal_eval(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df['client_funnel_client_lead_source_dict'] = df['client_funnel_client_lead_source'].apply(lambda x: get_dict(x))\n",
    "df['client_funnel_client_discovery_source_dict'] = df['client_funnel_client_discovery_source'].apply(lambda x: get_dict(x))\n",
    "df['client_funnel_client_origin_source_dict'] = df['client_funnel_client_origin_source'].apply(lambda x: get_dict(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669a098b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_lead(cell):\n",
    "    try:\n",
    "        if cell['description'] == 'Apartments.com':\n",
    "            return 'Apartments.com'\n",
    "        elif cell['description'] == 'Google':\n",
    "            return 'Google'\n",
    "        elif cell['description'] == 'Manual':\n",
    "            return 'Manual'\n",
    "        elif cell['description'] == 'Website':\n",
    "            return 'Website'\n",
    "        elif cell['description'] == 'Apartmentlist':\n",
    "            return 'Apartmentlist'\n",
    "        elif cell['description'] == 'Google My Business':\n",
    "            return 'Google My Business'\n",
    "        else:\n",
    "            return 'Other'\n",
    "    except:\n",
    "        return 'Other'\n",
    "\n",
    "def get_description(cell):\n",
    "    try:\n",
    "        return cell['description']\n",
    "    except:\n",
    "        return 'Unknown'\n",
    "    \n",
    "df['client_top_lead_source'] = df['client_funnel_client_lead_source_dict'].apply(lambda x: get_top_lead(x))\n",
    "df['client_all_lead_source'] = df['client_funnel_client_lead_source_dict'].apply(lambda x: get_description(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dc991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_discovery(cell):\n",
    "    try:\n",
    "        if cell['description'] == 'Apartments.com':\n",
    "            return 'Apartments.com'\n",
    "        elif cell['description'] == 'Google':\n",
    "            return 'Google'\n",
    "        elif cell['description'] == 'Website':\n",
    "            return 'Website'\n",
    "        elif cell['description'] == 'Resident Referral':\n",
    "            return 'Resident Referral'\n",
    "        elif cell['description'] == 'Zumper/Padmapper':\n",
    "            return 'Zumper/Padmapper'\n",
    "        elif cell['description'] == 'Craigslist':\n",
    "            return 'Craigslist'\n",
    "        else:\n",
    "            return 'Other'\n",
    "    except:\n",
    "        return 'Other'\n",
    "\n",
    "def get_description(cell):\n",
    "    try:\n",
    "        return cell['description']\n",
    "    except:\n",
    "        return 'Unknown'\n",
    "    \n",
    "df['client_top_discovery_source'] = df['client_funnel_client_discovery_source_dict'].apply(lambda x: get_top_discovery(x))\n",
    "df['client_all_discovery_source'] = df['client_funnel_client_discovery_source_dict'].apply(lambda x: get_description(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31779218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_origin(cell):\n",
    "    try:\n",
    "        if cell['description'] == 'Syndication Phone':\n",
    "            return 'Syndication Phone'\n",
    "        elif cell['description'] == 'Website - Appt Schedule':\n",
    "            return 'Website - Appt Schedule'\n",
    "        elif cell['description'] == 'Manual':\n",
    "            return 'Manual'\n",
    "        elif cell['description'] == 'Apartments.com':\n",
    "            return 'Apartments.com'\n",
    "        elif cell['description'] == 'Call Center':\n",
    "            return 'Call Center'\n",
    "        elif cell['description'] == 'Website':\n",
    "            return 'Website'\n",
    "        else:\n",
    "            return 'Other'\n",
    "    except:\n",
    "        return 'Other'\n",
    "\n",
    "def get_description(cell):\n",
    "    try:\n",
    "        return cell['description']\n",
    "    except:\n",
    "        return 'Unknown'\n",
    "    \n",
    "df['client_top_origin_source'] = df['client_funnel_client_origin_source_dict'].apply(lambda x: get_top_origin(x))\n",
    "df['client_all_origin_source'] = df['client_funnel_client_origin_source_dict'].apply(lambda x: get_description(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c42af4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['client_funnel_client_lead_source_dict', 'client_funnel_client_discovery_source_dict', \n",
    "         'client_funnel_client_origin_source_dict'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fde4d8d",
   "metadata": {},
   "source": [
    "# 3. clean target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477c6bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['client_funnel_is_rented'].value_counts(normalize=True)\n",
    "\n",
    "#IMPT: target is skewed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d63f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop nulls in target\n",
    "\n",
    "df['client_funnel_is_rented'].isna().sum() / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490d84a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['client_funnel_is_rented'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047b72c4",
   "metadata": {},
   "source": [
    "# 3. feature engineering: stage 2 model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d7d13d",
   "metadata": {},
   "source": [
    "## 3.1. avg_convo_text_length\n",
    "= average text length across all recorded conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f393ed9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_length(x):\n",
    "    try: \n",
    "        if np.isnan(x):\n",
    "            return np.nan\n",
    "    except:\n",
    "        return len(x)\n",
    "\n",
    "df2['convo_text_length'] = df2['conversations_message_text'].apply(lambda x: get_length(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa14d80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2['avg_convo_text_length'] = df2.groupby(['client_id', 'group_id'])['convo_text_length'].transform(lambda x: x.sum() / len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d72873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['avg_convo_text_length'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7205f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop(['conversations_message_text', 'convo_text_length'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6257945b",
   "metadata": {},
   "source": [
    "## 3.2. num_conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dbbf94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num = df2.groupby(['client_id', 'group_id']).transform(lambda d: len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eabe81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['num_conversations'] = num.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eb986d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#account for rows that have nulls for conversation variables: num_conversations should be 0 but they are non-zero from the above len() method\n",
    "\n",
    "no_conversation_indexes = df2[df2['conversations_medium'].isnull()].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10470a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[no_conversation_indexes, 'num_conversations'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fefa50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df2['num_conversations'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82db129",
   "metadata": {},
   "source": [
    "## create vars: count of each medium used for convo, count of all mediums used, count of each direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651916ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def get_counts(row):\n",
    "    medium_counts = collections.Counter(row['conversations_medium'])\n",
    "    direction_counts = collections.Counter(row['conversations_direction'])\n",
    "    return (medium_counts, direction_counts)\n",
    "    \n",
    "counts = df2.groupby(['client_id', 'group_id']).apply(lambda d: get_counts(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad59565",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = counts.reset_index()\n",
    "counts = counts.rename(columns = {0: 'counts'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb93466",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ff7d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop(['conversations_medium', 'conversations_direction'], axis = 'columns', inplace=True)\n",
    "df2.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c8c257",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ec8b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.merge(counts, how='left', on=['client_id', 'group_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75b4907",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean 'counts' col\n",
    "\n",
    "def clean_counts(x):\n",
    "    medium_counts = {'phone': 0, 'email': 0, 'sms': 0, 'other': 0}\n",
    "    direction_counts = {'incoming': 0, 'outgoing': 0}\n",
    "    num_total_mediums = 0\n",
    "    \n",
    "    medium_dict = x[0]\n",
    "    direction_dict = x[1]\n",
    "    \n",
    "    for key, val in medium_dict.items():\n",
    "        if key == 'Phone':\n",
    "            medium_counts['phone'] = val\n",
    "            num_total_mediums += 1\n",
    "        elif key == 'Email Message':\n",
    "            medium_counts['email'] = val\n",
    "            num_total_mediums += 1\n",
    "        elif key == 'SMS Message':\n",
    "            medium_counts['sms'] = val\n",
    "            num_total_mediums += 1\n",
    "        elif key == 'Other Message Type':\n",
    "            medium_counts['other'] = val\n",
    "            num_total_mediums += 1\n",
    "    \n",
    "    for key, val in direction_dict.items():\n",
    "        if key == 'Incoming':\n",
    "            direction_counts['incoming'] = val\n",
    "        elif key == 'Outgoing':\n",
    "            direction_counts['outgoing'] = val\n",
    "        \n",
    "    return num_total_mediums, medium_counts['phone'], medium_counts['email'], medium_counts['sms'], medium_counts['other'], direction_counts['incoming'], direction_counts['outgoing']\n",
    "\n",
    "df2['num_total_mediums'], df2['medium_phone_count'], df2['medium_email_count'], df2['medium_sms_count'], df2['medium_other_count'], df2['direction_incoming_count'], df2['direction_outgoing_count'] = zip(*df2['counts'].map(clean_counts))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad8ce99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop('counts', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a498ea",
   "metadata": {},
   "source": [
    "# 4. build model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68bee02",
   "metadata": {},
   "source": [
    "## 4.1. CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c01d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import  auc, roc_curve, precision_recall_curve, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643f5fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stage1 = df[['group_assignment_company_id', 'client_funnel_layout_type', 'client_funnel_community_name', \n",
    "                'client_top_lead_source', 'client_top_discovery_source', 'client_top_origin_source', \n",
    "                'client_all_lead_source', 'client_all_discovery_source', 'client_all_origin_source',\n",
    "                'client_funnel_new_lead_group', 'client_funnel_is_walk_in', \n",
    "                'timediff_firsttouch_leadcreation', 'client_funnel_first_touch_medium', \n",
    "                'timediff_category_group_lead_creation', 'client_funnel_is_rented']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce13f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stage1.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e927ff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stage1['client_funnel_is_walk_in'] = df_stage1['client_funnel_is_walk_in'].apply(lambda x: int(x))\n",
    "df_stage1['client_funnel_new_lead_group'] = df_stage1['client_funnel_new_lead_group'].apply(lambda x: int(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aab7f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_f = []  #insert categorical feature names here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bafcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_stage1.drop('client_funnel_is_rented', axis=1)\n",
    "y = df_stage1[\"client_funnel_is_rented\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d529d643",
   "metadata": {},
   "source": [
    "### 4.1.1 tune CatBoost using Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa11f637",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost = CatBoostClassifier(loss_function='Logloss', cat_features=categorical_f, one_hot_max_size=7, verbose=10)\n",
    "# one_hot_max_size = 7 so that layout_type, new_lead_group, and other columns with many levels will be processed using CatBoost's integrated target statistics\n",
    "\n",
    "param = {\n",
    "    'iterations':Integer(100, 250), # on the low side to speed up computation (learning rate will adjust accordingly)\n",
    "    'depth':Integer(1, 10),\n",
    "    'random_strength':Real(1e-9, 10), # amount of randomness to use for scoring splits (used to prevent overfitting)\n",
    "    #'bagging_temperature':Real(0.0, 1.0),\n",
    "    'l2_leaf_reg':Real(0.001, 10000), # coefficient at the L2 regularization term (lambda)\n",
    "    'scale_pos_weight':Real(1, 50), # weight for class 1 in binary classification\n",
    "    'subsample':Real(0.5, 1),\n",
    "    'colsample_bylevel':Real(0.5,1),\n",
    "    'model_size_reg':Real(0.01, 1000), # model size regularization coefficient\n",
    "    'leaf_estimation_iterations':[1,5] # how many steps are done in every tree when calculating leaf values (values recommendated in documentation)\n",
    "}\n",
    "\n",
    "LogLoss = make_scorer(log_loss, greater_is_better=False, needs_proba=True) \n",
    "    \n",
    "opt = BayesSearchCV(catboost, param, scoring = LogLoss, n_iter=20, cv=3, random_state=101, verbose=1)\n",
    "\n",
    "# executes bayesian optimization\n",
    "opt.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a2c9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75683bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the best parameters in this dictionary\n",
    "best_para = {\n",
    "    'iterations': 250,\n",
    "    'depth': 9,\n",
    "    'random_strength': 1e-9,\n",
    "    'l2_leaf_reg': 0.001,\n",
    "    'scale_pos_weight':1.0,\n",
    "    'subsample':1.0,\n",
    "    'colsample_bylevel':0.5,\n",
    "    'model_size_reg': 0.01,\n",
    "    'leaf_estimation_iterations': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2804ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost = CatBoostClassifier(**best_para, cat_features=categorical_f, loss_function='Logloss', one_hot_max_size=7)\n",
    "catboost.fit(X_train, y_train, verbose=30)\n",
    "proba_cat = catboost.predict_proba(X_test)[:, 1]\n",
    "y_pred=catboost.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, proba_cat)\n",
    "auc_ = auc(fpr, tpr)\n",
    "precision, recall, thresholds_2 = precision_recall_curve(y_test, proba_cat)\n",
    "auc_2 = auc(recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd71ec0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Preliminary', fontsize=20)\n",
    "plt.plot(recall, precision, 'b', label = 'AUC = %0.2f' % auc_2, color='#ff00ff', linewidth=3)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1],[0.158,0.158], color='#ffffff', linestyle='--', linewidth=3)\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('Precision', fontsize=14)\n",
    "plt.xlabel('Recall', fontsize=14)\n",
    "plt.yticks(size = 14)\n",
    "plt.xticks(size = 14)\n",
    "plt.style.use('seaborn')\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde9a17c",
   "metadata": {},
   "source": [
    "### 4.1.2 get permutation feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85650f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = catboost.get_feature_importance(prettified=True, thread_count=-1, verbose=False).set_index('Feature Id')\n",
    "plt.rcParams[\"figure.figsize\"] = (12,7)\n",
    "ax = importance.plot(kind='barh', color='#ff00ff')\n",
    "plt.style.use('seaborn-bright')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa09285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_importances(model, X, y, metric):\n",
    "    baseline = metric(model, X, y)\n",
    "    imp = []\n",
    "    for col in X.columns:\n",
    "        save = X[col].copy()\n",
    "        X[col] = np.random.permutation(X[col])\n",
    "        m = metric(model, X, y)\n",
    "        X[col] = save\n",
    "        imp.append(m-baseline)\n",
    "    return np.array(imp)\n",
    "\n",
    "def get_feature_imp_plot(model, method):\n",
    "    \n",
    "    fi =  permutation_importances(model, X_test, y_test, LogLoss)\n",
    "    feature_score = pd.DataFrame(list(zip(X_test.dtypes.index, fi )),\n",
    "                                    columns=['Feature','Score'])\n",
    "\n",
    "    feature_score = feature_score.sort_values(by='Score', ascending=False, inplace=False, kind='quicksort', na_position='last')\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (12,7)\n",
    "    ax = feature_score.plot('Feature', 'Score', kind='barh', color='c')\n",
    "    ax.set_title(\"Feature Importance using {}\".format(method), fontsize = 14)\n",
    "    ax.set_xlabel(\"features\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2da841",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time get_feature_imp_plot(catboost, method=\"Permutation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5126377d",
   "metadata": {},
   "source": [
    "### 4.1.3 get SHAP feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2c94c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a896c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(catboost)\n",
    "shap_values = explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58498d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test, use_log_scale=True)\n",
    "\n",
    "#X-axis: log odds of renting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dde3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values, max_display=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fc62bf",
   "metadata": {},
   "source": [
    "## 4.2. logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021ac913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd849ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "logr = LogisticRegression()\n",
    "logr.fit(x_train, y_train)\n",
    "proba_li = logr.predict_proba(x_test)[:, 1]\n",
    "y_pred = logr.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bd8d1e",
   "metadata": {},
   "source": [
    "## 4.3. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdfd9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff884d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(max_depth=3,eta=0.1, colsample_bytree = 0.8,subsample=0.8)\n",
    "xgb.fit(x_train, y_train)\n",
    "proba_xgb = xgb.predict_proba(x_test)[:, 1]\n",
    "y_pred = xgb.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e40fd0",
   "metadata": {},
   "source": [
    "### 4.3.1. get permutation feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc16930",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_important = xgb.get_booster().get_score(importance_type='permutation')\n",
    "keys = list(feature_important.keys())\n",
    "values = list(feature_important.values())\n",
    "\n",
    "data = pd.DataFrame(data=values, index=keys, columns=[\"score\"]).sort_values(by = \"score\", ascending=False)\n",
    "data.plot(kind='barh')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
